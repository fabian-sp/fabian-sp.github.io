---
permalink: /
title: "Home"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

About me
-------------
I am a researcher working on Optimization for Machine Learning. Currently, I am a postdoc at Inria Paris, in the team of Francis Bach. I obtained my PhD at TUM (Technical University of Munich), supervised by Professor Michael Ulbrich. You can contact me at firsstname.lastname@tum.de.

My research interests are mainly stochastic optimization algorithms for machine learning, and related topics in computation and statistics. My recent work focuses on how to reduce the tuning effort for algorithms like SGD or Adam with adaptive learning rates. In this line of work, we developped (i) a way to include regularization functions in stochastic Polyak stepsizes (**ProxSPS**, [link to paper](https://openreview.net/forum?id=jWr41htaB3)), and (ii) how to combine adaptive learning rates with any preconditioned momentum method such as SGD-M an Adam (**MoMo**, [link to paper](https://arxiv.org/abs/2305.07583)).

News
----------

* July 2024: I successfully defended my PhD thesis!
* August - October 2023: Visiting researcher at CCM, Flatiron Institute, New York City.
* June 2023: Participated in the [ProbAI summer schol](https://probabilistic.ai/) in Trondheim, Norway.